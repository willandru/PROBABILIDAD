Inferencia

Teoria de la informacion: no se hace en rigor en este curso
	Concenpto de ergorisidad, entropia


ESPACIO DE PROBABILIDAD: Todas as reglas, la union la independencia, etc

MODELOS UNIVARIADOS: Discretos y COntinuos y mezclados

MODELOS MULTIVARIADOS: Conceptos vimos, vimos lo fundamental en 2 variables, independencia, variazan conjunta, correlacion y condicional.

ESTADISTICA: Modelos estadisticos 
			 Inferencial

		MOdelos:

		modelos lineales y no lineales: redes neuronales, arboles de descicion bayesiano, IA

	ESTADISTICA BAYESIANA : estuvo muerta pues tenia calculos muy pesados, desde el 90 ha tenido un fuerte desarrollo. Teoria de aprendizaje. HACER APRENDER UN ROBOT, mucho la parte bayesiana


INFERENCIA ESTADISTICA:

Una empresa tienen un problema y debe analizarlo para un su poblacion, pero es muuuy grande y no se puede analizar a todos los individusos de la poblacion. 
Estadisticamente, la poblacion se representa como un un MODELO DE UNA VARIABLE ALEATORIA. Un modelo puede ser la v.a X, o puede ser la F.D

Poblacion: De acuerdo al problema que caracteristica va a estudiar; empleo, tasa de desercion, etc.

Se saca UNA MUESTRA de la población, con la que se hace un analisis estadistico para decir algo del problema


POBLACION: Una caractersitica que uno quiere medir: UNA VARIABLE ALEATORIA: VIenen estratificadas en los mundos DISCRETOS y CONTINUOS, pero ademas de la maenra en la que se le toman los datos a la poblacion, puede ser ORDINAL, CATEGORICO, NOMINAL, etc.


MUESTRA: muestra aleatoria y en la primera etapa debe ser simple (m.a.s) : X1, X2, X3, ... , Xn  son independientes e identicamente distribuidas (i.i.d)

Identicas: Todas las Xj tienen la misma F.D de X
Independientes: F_x1,x2,...,xn = Fx1 * Fx2 * Fx3 * .... * Fxn


X --> FD   F_x(x;theta)

TEORMEA DEL LIMITE CENTRAL: TEOREMA CENTRAL DEL LIMITE

	DESIGUALDADES
	 Desigualdad de MArkov
	 Desigualdad de Chebyshev

	DESIGUALDAD DE JENSEN

	DISTRIBUCIONES MUESTRALES

	TEOREMA CENTRAL DEL LÍMITE

	DISTRIBUCIONES MUESTRALES ASOCIADAS CON POBLACIONES NORMALES
	 Distribución Chi-Cuadrado
	 Distribución t-student
	 Distribución F de Fisher

	ESTADISTICA DE ORDEN

	ESTADISTICA PUNTUAL

::
-----------------------
DESIGUALDAD DE MARKOV:: Le permite hacer cuentas de cosas en las variable saleatorias , con cualquier v.a, la condicion es que sea positiva y valor esperado menor que infinito

--RESULTA ue las poblaciones tienen unas caracteristicas de cola, donde tienen concentrada su probabilidad en el centro y tenemos, distribuciones con cola pesada a la izquierda, a la derecha, TEORIA DE COLAS, colas gordas , coals pesadas.

--LO QUE DICE EL TEOREMA DE MARKOV es que si uno coloca un punto en cualquier parte de la poblacion y uno analiza la cola derecha, ese analisis se hace por la probabilidad  (P(x>=a)) de que pase un umbral, y este teorema dice que esta probabilidad es menor que el valor esperado de la variable dividido en "a"

EJEMPLO: Un profesor sabe que el puntaje de un examen es una variable aleatoria con media 75 puntos. Determine una cota superior para la probabilidad de que un estudiante obtenga un puntaje de por lo menos 85 puntos.

		P(X>=85) <= 75/85 ~= 0.882

Por mucho el 88% de los estidantes tienen un puntaje superior a 85  puntos.  
--

Cunado uno toma la constante "a" como un multiplo del promedio "miu", entonces esta desigualdad se transfomra en : 
		P(X>=k*miu) <= 1/k

		k=1  -> P = 1
		k=2  -> P=1/2  --> El 50% de los datos se encuentra en...

Banda limitada una señal: Es una modificacion del tweorema pero con una cota.  P(X<=x) <= (M-miu)/(M-x)
-----------------------

DESIGUALDAD DE CHEBYSHEV:

Solo tiene en cuenta el VALOR ESPERADO E(X)
Una variable aleatoria cualquiera, no necesariamente positiva, con valor esperado < infinito y varianza finita.

Probo que los datos de la variable X sercanos a su promedio, y que superan un umbral epsilon, no superan el valor de 
       varianza/epsilon^2

       FILTROS DE CHEBYSHEV
    EJEMPLO

    Lanzar una moneda n veces hasta obtener exito.

    X~Bin(n, 1/2) 
    E(x) = n/2
    Var(x)= n*(1/2)*(1/2)= n/4

    	--->	P(|X-E(X)|>= n/3) <= (n/4)/(n/3)² = 9/4n

    EJEMPLO: Existe alguna variable aleatoria X, con media miu y varianza sigma² tal que 
      P(miu-2*sigma <= X <= miu + 2*sigma) = 0.6

      P(-2*sigma <= X-miu <= 2*sigma) = 0.6
      P(|X-miu| <= 2*sigma) = 0.6
      P(|X-miu| >= 2*sigma) = 0.4

      	Chebychev:  P(|X-miu| >= 2*sigma) <=  (sigma²/(2*sigma)²) = 1/4 =0.25

      	No es posible

     EJEMPLO: Suponga que en promedio una empresa de envios maneja 10.000 envios mensualmente, con una varianza de 2.000. Analizar la probabilidad de que esta empresa meneje entre 8.000 y 12.000 envios en el siguiente mes.

     X: #Envios mensuales.
     E(x)= 10.000 = miu
     Var(x)= 2.000 = sigma²

     P(8000 <= X <= 12000) = P(-2000 <= X-miu <= 2000)
     					   = P(-sigma² <= X-miu <= sigma²)
     					   = P( |X-miu|<= sigma²)
     					Chebychev: 
     					P(|X-miu| >= epsilon) <= sigma²/epsilon²
     			P(|X-miu| <= epsilon) >= 1 - (sigma²)/(epsilon²)
     			P(|X-miu| <= sigma²) >= 1 - (sigma²)/(sigma²)² 
     				= 1- 1/4 = 0.75 
     				La probaiblidad de que so ocurra no es mayor a 0.75

  